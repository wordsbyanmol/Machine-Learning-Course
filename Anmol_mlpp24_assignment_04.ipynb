{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wordsbyanmol/Machine-Learning-Course/blob/main/Anmol_mlpp24_assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugGDuuAUpZEQ"
      },
      "source": [
        "# **MLPP24 // Assignment #4**\n",
        "\n",
        "assigned : **Mar 7, 2024**\n",
        "\n",
        "DUE : **Mar 22, 2024 11:59pm**\n",
        "\n",
        "## Outcomes of gentrification: local changes to median income\n",
        "\n",
        "<img src=\"https://cdn.theatlantic.com/assets/media/img/mt/2015/08/20720085886_db5d1f89e8_o/lead_720_405.jpg?mod=1533691764\" width=500>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQgC1Td2qSkW"
      },
      "source": [
        "<b>\n",
        "\n",
        "How to complete and submit assignments:\n",
        "\n",
        "1. Please make a copy of this notebook in your Google Drive and add your name to the filename.\n",
        "\n",
        "2. Once you have completed the notebook, please share it with me before the due date and time by clicking the \"Share\" button in the upper right corner of the notebook.\n",
        "\n",
        "\n",
        "Rules for assignments:\n",
        "\n",
        "1. You may work with other students in the class, but if you do, each student with whom you worked <u>must</u> be listed below.  Direct copying from someone else's notebook is not permitted.\n",
        "\n",
        "2. You may use generative AI models (e.g., ChatGPT) to help complete the assignment but if you do you must answer YES to the question below and bear in mind that such models <u>often</u> yield incorrect and biased solutions.\n",
        "\n",
        "3. All solutions and outputs must be derived with python and the notebook should be \"runable\" by me (top to bottom) without errors.\n",
        "\n",
        "4. Late assignments will assess a 15% late penalty up to 3 days after the due date and a 50% late penalty until the end of the term.\n",
        "\n",
        "</b>\n",
        "\n",
        "<u>**Instructions for tasks that will be graded are in bold below.**</u>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLCF0L1pwLKG"
      },
      "source": [
        "**Please list the names of the other students with whom you worked for this assignment (if none, put \"None\").**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNqbLdWQwNFb"
      },
      "source": [
        "TEXT FOR YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did you use a generative AI model (e.g., ChatGPT) to create text or code for this assignment?**"
      ],
      "metadata": {
        "id": "QpG_Q-bz8Tlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes"
      ],
      "metadata": {
        "id": "PYBvVTai8Wj9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ1-4OjvwOEa"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In class we discussed the definition of gentrification and the outcomes associated with that process.  Our specific example was the changing demographic makeup of Philadelphia over the period of 2000 to 2016.  In this assignment, we'll be doing an identical comparison, but considering local changes to median income.\n",
        "\n"
      ],
      "metadata": {
        "id": "evTAanSY8gEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CAPM_0E54VgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBL4OBtWzv7O"
      },
      "source": [
        "### **PART 1 - Loading and Working With the Census Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB_Vx2NoV3aF"
      },
      "source": [
        "<b> Link your google drive and install geopandas. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaEJO3-xVw9K"
      },
      "source": [
        "#import libraries for analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import geopandas as gp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-O7EEz4MVGr"
      },
      "source": [
        "<b> Load in the pre-cleaned 2000 median income data from the `data/census/income/` directory <u>as well as</u> the 2000 and 2016 shapefiles (in the `data/census/ctshapes` directory).  Make sure that you call the census tract GeoDataFrames `ct00` and `ct16`.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8y6UVujfx_W"
      },
      "source": [
        "#load data from Drive\n",
        "fname= \"/content/drive/Shareddrives/mlpp24/data/census/income/census_income_2000.csv\"\n",
        "\n",
        "median_income= pd.read_csv(fname)\n",
        "median_income_copy= median_income\n",
        "median_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKpR2jEPfyrr"
      },
      "source": [
        "<b>\n",
        "\n",
        "Load the 2016 ACS 5-year estimates for the median income for census tracts from `data/census/income/` and drop all rows for which the median income (column `\"B19013_001E\"`) is equal to `-666666666`.\n",
        "\n",
        "</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6ikBszLw2uK"
      },
      "source": [
        "#load data from Drive\n",
        "fname2016= \"/content/drive/Shareddrives/mlpp24/data/census/income/census_income_2016.csv\"\n",
        "\n",
        "acs16= pd.read_csv (fname2016)\n",
        "acs16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each value in the column\n",
        "value_counts = acs16['B19013_001E'].value_counts()\n",
        "value_counts\n",
        "\n",
        "if -666666666 in value_counts:\n",
        "    print(f\"Number of rows with value -666666666: {value_counts[-666666666]}\")\n",
        "else:\n",
        "    print(\"There are no rows with value -666666666 in the specified column.\")"
      ],
      "metadata": {
        "id": "nhKGUc7nB8n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with median income equal to -666666666\n",
        "acs16= acs16[acs16['B19013_001E'] != -666666666]\n",
        "\n",
        "# Display the dataframe\n",
        "print(acs16)"
      ],
      "metadata": {
        "id": "lPNIK4v8-mR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx7eVMsratev"
      },
      "source": [
        "<b> In the income DataFrames, rename the column `\"Median household income in 1999\"` to `\"income_2000\"` and the column `\"B19013_001E\"` to `\"income_2016\"` (print the heads of the DataFrames to see if it worked).</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUrA2VLsQAx5"
      },
      "source": [
        "# Rename columns\n",
        "median_income.columns = ['Id2_2000', 'income_2000']\n",
        "\n",
        "# Display the DataFrame with renamed columns\n",
        "median_income. head ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns\n",
        "acs16.columns =['income_2016', 'GEOID']\n",
        "\n",
        "# Display the DataFrame with renamed columns\n",
        "acs16"
      ],
      "metadata": {
        "id": "BO7mIKEwIPEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flcEZHqEQvgX"
      },
      "source": [
        "In order to compare 2000 dollars to 2016 dollars we need to adjust for inflation.  We could assume a model for inflation, but instead, let's just adjust the 2000 data so that it has the same mean as the 2016 data.\n",
        "\n",
        "<b> First, plot a histogram of the 2000 incomes and a histogram of the 2016 incomes (on the same plot) each with 50 bins and range 0 to 140000 and `alpha=0.5`. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOv2PZjKRPMt"
      },
      "source": [
        "# Plot histograms for incomes in 2000 and 2016 on the same plot\n",
        "plt.hist(median_income[\"income_2000\"], bins=50, range=(0, 140000), alpha=0.5, label='2000')\n",
        "plt.hist(acs16[\"income_2016\"], bins=50, range=(0, 140000), alpha=0.5, label='2016')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Income')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Median Income for 2000 and 2016')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI49lbw9SKK_"
      },
      "source": [
        "You can see that the 2016 incomes are a bit higher on average.\n",
        "\n",
        "<b> Now calculate the ratio between the mean 2016 income and mean 2000 income.  Create a column in the 2000 income DataFrame called `\"income_2000_adj\"` that is `\"income_2000\"` times that ratio.  Print the mean of `\"income_2016\"` and `\"income_2000_adj\"` to make sure that they are now the same and replot the histograms above with the 2016 and 2000 adjusted incomes. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN282Q48TNdf"
      },
      "source": [
        "# Calculate the mean income for 2016\n",
        "mean_income_2016 = acs16['income_2016'].mean()\n",
        "\n",
        "# Calculate the mean income for 2000\n",
        "mean_income_2000 = median_income['income_2000'].mean()\n",
        "\n",
        "# Calculate the ratio\n",
        "income_ratio = mean_income_2016 / mean_income_2000\n",
        "\n",
        "print(\"Mean income in 2016:\", mean_income_2016)\n",
        "print(\"Mean income in 2000:\", mean_income_2000)\n",
        "print(\"Income ratio (2016/2000):\", income_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a column in the 2000 income DataFrame called \"income_2000_adj\"\n",
        "median_income[\"income_2000_adj\"] = median_income[\"income_2000\"]* income_ratio\n",
        "median_income. head ()"
      ],
      "metadata": {
        "id": "Lw-QMlCqbybc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean of income_2016 column\n",
        "mean_income_2016 = acs16[\"income_2016\"].mean()\n",
        "\n",
        "# Calculate the mean of income_2000_adj column\n",
        "mean_income_2000_adj = median_income[\"income_2000_adj\"].mean()\n",
        "\n",
        "# Print the means\n",
        "print(mean_income_2016)\n",
        "print(mean_income_2000_adj)"
      ],
      "metadata": {
        "id": "Zm_BBwxadhF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median_income. head ()"
      ],
      "metadata": {
        "id": "_MIrV6mhcRJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histograms for incomes in 2000 and 2016 on the same plot\n",
        "plt.hist(median_income[\"income_2000_adj\"], bins=50, range=(0, 140000), alpha=0.5, label='2000')\n",
        "plt.hist(acs16[\"income_2016\"], bins=50, range=(0, 140000), alpha=0.5, label='2016')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Income')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Median Incomes for 2000 and 2016')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P93HULknfnLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqezqv5uUQt2"
      },
      "source": [
        "The 2000 incomes have now been adjusted to 2016 levels$^{\\dagger}$ so that we can now take meaningful differences.\n",
        "\n",
        "<small>$^{\\dagger}$ under several assumptions! </small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KwDRW3R2qEU"
      },
      "source": [
        "### **PART 2 - Merging and Visualizing the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmbqL9bboYlJ"
      },
      "source": [
        "Now we'd like to make some maps of the income data.  Before we do that, we need to clean up the census tract GeoDataFrames a bit.\n",
        "\n",
        "<b>As we did in class, create a proper `\"GEOID\"` for year 2000 and convert both year 2000 and year 2016 `\"GEOID\"`s into integers.</b>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z17PSPq6jHPq"
      },
      "source": [
        "#load files\n",
        "fname00= \"/content/drive/Shareddrives/mlpp24/data/census/ctshapes/2000/tr42_d00.shp\"\n",
        "fname16= \"/content/drive/Shareddrives/mlpp24/data/census/ctshapes/2016/cb_2016_42_tract_500k.shp\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#name files\n",
        "ct00 = gp.read_file(fname00)\n",
        "ct16 = gp.read_file(fname16)"
      ],
      "metadata": {
        "id": "Kc0Adb2E-_cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median_income. head ()"
      ],
      "metadata": {
        "id": "AHzx7kHhBLk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct00.plot ()"
      ],
      "metadata": {
        "id": "UUbEjBzMAPPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct00"
      ],
      "metadata": {
        "id": "fRjUs1BPAHr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_states = ct00[\"STATE\"].unique()\n",
        "print(unique_states)"
      ],
      "metadata": {
        "id": "19U2zfq_a9Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#string manipulation\n",
        "# Concatenate the values of the three columns into a new column\n",
        "\n",
        "state = ct00['STATE']\n",
        "county= ct00['COUNTY']\n",
        "tract = ct00[\"TRACT\"]\n",
        "tract= tract + \"00\"\n",
        "tract= tract.str[:6]\n",
        "geoid= state+county+tract\n",
        "ct00[\"GEOID\"]= geoid\n",
        "\n",
        "# Display the DataFrame with the new column\n",
        "ct00"
      ],
      "metadata": {
        "id": "aYfF30MoHCqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct00[\"GEOID\"].info ()"
      ],
      "metadata": {
        "id": "_Ipz3lB6KEEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the new column to integers\n",
        "ct00['GEOID'] = ct00['GEOID'].astype(int)\n",
        "ct00. info ()"
      ],
      "metadata": {
        "id": "FgCbVEQ1AXv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct16.head ()"
      ],
      "metadata": {
        "id": "iEtKvHHSK4S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert column to integers\n",
        "ct16['GEOID'] = ct16['GEOID'].astype(int)\n",
        "ct16. info ()"
      ],
      "metadata": {
        "id": "A4Bw5VL9KuT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty4vQKvjWCEn"
      },
      "source": [
        "<b> Now, merge the 2000 income data into the 2000 census tract GeoDataFrame, creating a new GeoDataFrame called `inc00sh`, and merge the 2016 income data into the 2016 census tract GeoDataFrame creating a new GeoDataFrame called `inc16sh`.</b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "median_income. head(2)"
      ],
      "metadata": {
        "id": "mkovZFE3O9B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct00. head (2)"
      ],
      "metadata": {
        "id": "lDaTZ67JPSdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0feGkNqoWyyY"
      },
      "source": [
        "#merge dataframe\n",
        "inc00sh= ct00.merge(median_income, left_on= \"GEOID\", right_on= \"Id2_2000\")\n",
        "inc00sh. head (3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inc00sh[\"COUNTY\"].value_counts ()"
      ],
      "metadata": {
        "id": "tLMatoNP90NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "na_count = inc00sh['income_2000_adj'].isna().sum()\n",
        "print(\"Number of NaN values in 'income_2000_adj' column:\", na_count)\n",
        "\n",
        "# Remove NaN values from a specific column\n",
        "inc00sh = inc00sh.dropna(subset=['income_2000_adj'])\n",
        "inc00sh. head (3)\n"
      ],
      "metadata": {
        "id": "adsnIywXYTLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing or invalid geometries\n",
        "inc00sh = inc00sh.dropna(subset=['geometry'])\n",
        "inc00sh = inc00sh[inc00sh.geometry.is_valid]\n",
        "\n"
      ],
      "metadata": {
        "id": "7rx4qrWRKJLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge dataframe\n",
        "inc16sh= ct16.merge(acs16, left_on= \"GEOID\", right_on= \"GEOID\")\n",
        "inc16sh. head ()"
      ],
      "metadata": {
        "id": "jTXarYxeP5Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inc16sh.info ()"
      ],
      "metadata": {
        "id": "T7B1uFQoLKvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop missing or invalid geometries\n",
        "inc16sh = inc16sh.dropna(subset=['geometry'])\n",
        "inc16sh = inc16sh[inc16sh.geometry.is_valid]"
      ],
      "metadata": {
        "id": "VdAm_NIHK7dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the adjusted 2000 incomes on a map\n",
        "labs = {\"income_2000_adj\": \"Median Adjusted Income for 2000\"}\n",
        "fig = px.choropleth_mapbox(inc00sh, geojson=inc00sh.set_index(\"GEOID\"),\tlocations= \"GEOID\",\n",
        "color= \"income_2000_adj\", opacity= 0.75,\n",
        "color_continuous_scale= \"viridis\",\n",
        "title= \"Pennsylvania\",\n",
        "mapbox_style= \"carto-positron\",\n",
        "center={\"lon\":-75.15, \"lat\": 40.00},\n",
        "zoom=9.5, height= 600, width= 900, labels= labs)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ocX7K8WeZEXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the adjusted 2016 incomes on a map\n",
        "labs = {\"income_2016\": \"Median Income for 2016\"}\n",
        "fig = px.choropleth_mapbox(inc16sh, geojson=inc16sh.set_index(\"GEOID\"),\tlocations= \"GEOID\",\n",
        "color= \"income_2016\", opacity= 0.75,\n",
        "color_continuous_scale= \"viridis\",\n",
        "title= \"Pennsylvania\",\n",
        "mapbox_style= \"carto-positron\",\n",
        "center={\"lon\":-75.15, \"lat\": 40.00},\n",
        "zoom=9.5, height= 600, width= 900, labels= labs)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CqGKcl9u-4Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuMxOaA7jlp3"
      },
      "source": [
        "<b> Plot the adjusted 2000 incomes on a map with `vmin=20000` and `vmax=120000`.  Do the same for the 2016 incomes.  Make sure to include the legend (colorbar) and add text to indicate what those color values represent.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOg-1m7ClDVW"
      },
      "source": [
        "We can already see some differences popping out, especially with respect to Center City (and Fishtown) and North Philadelphia.  To properly visulize those, we'd like to take the difference of these two maps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hWRDxypowOU"
      },
      "source": [
        "### **PART 3 - Interpolating the 2000 data on 2016 Locations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KDRLmj9m-iT"
      },
      "source": [
        "In class, merging the 2000 data into the 2016 GeoDataFrame resulted in a lot of dropped census tracts b/c the definition of the census tracts changed over time.  To recover those, we need an estimate of the adjusted 2000 income value at each 2016 census tract.  We can do this by interpolating (using Gaussian Process Regression [aka Kriging]) the adjusted 2000 values onto the 2016 locations.\n",
        "\n",
        "<b> Import the GaussianProcessRegressor model as well as the ConstantKernel and RBF kernels. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwd45BkGpf16"
      },
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyXw9uQ9pq59"
      },
      "source": [
        "<b> As we did in class, create the features (lat/lon) and target (2000 adjusted median incomes) for the model from the `inc00sh` GeoDataFrame. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrxdDAu4pqwK"
      },
      "source": [
        "lon00 = inc00sh.centroid.x\n",
        "lat00 = inc00sh.centroid.y\n",
        "\n",
        "lon16 = inc16sh.centroid.x\n",
        "lat16 = inc16sh.centroid.y\n",
        "\n",
        "fig, ax= plt.subplots(figsize=(8,6))\n",
        "ax.scatter(lon00, lat00, facecolor= \"none\", color= \"k\", s=60, label=\"2000 centroids\")\n",
        "ax.scatter(lon16, lat16, c= \"r\", s=20, label=\"2016 centroids\")\n",
        "ax.legend()\n",
        "ax.axis(\"equal\")\n",
        "fig.show ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbncPrTsqYXE"
      },
      "source": [
        "As always, the features need to be standardized.\n",
        "\n",
        "<b> Standardize the features array across objects and standardize the target. </b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inc00sh. head (2)"
      ],
      "metadata": {
        "id": "qqzKsYcnFnae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpNsi6sdpqlp"
      },
      "source": [
        "# Features\n",
        "feat= pd.DataFrame ()\n",
        "feat[\"lon\"] = lon00\n",
        "feat[\"lat\"] = lat00\n",
        "\n",
        "# Target\n",
        "targ = inc00sh[\"income_2000_adj\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features\n",
        "feat_st = (feat - feat.mean()) / feat.std()\n",
        "# Standardize target\n",
        "targ_st = (targ - targ.mean()) / targ.std()"
      ],
      "metadata": {
        "id": "fsRhYhQ3qDVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gYITMYQrxAr"
      },
      "source": [
        "<b> Fit a GPR model to the standardized 2000 data (remember to intialize the kernel).</b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialise kernel and fit into data\n",
        "kernel= C(1.0,(1e-3, 1e3)) * RBF(10., (1e-2, 1e2))\n",
        "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gpr.fit(feat_st, targ_st)"
      ],
      "metadata": {
        "id": "SjSuFpIQswVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64guhWrhr0_3"
      },
      "source": [
        "#create the feature array of prediction\n",
        "feat_pred=pd.DataFrame ()\n",
        "feat_pred [\"lon\"]= lon16\n",
        "feat_pred [\"lat\"]= lat16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZARvLqFQsHXM"
      },
      "source": [
        "The model has now been fit to the 2000 adjusted median income data at the 2000 census tract locations.  Now we want to interpolate onto the 2016 positions.\n",
        "\n",
        "<b> Create features for the 2016 census tract positions making sure to standardize. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbF8TK3zsdCt"
      },
      "source": [
        "# Standardize target\n",
        "feat_pred_std= (feat_pred - feat.mean()) / feat.std()\n",
        "\n",
        "#make prediction\n",
        "inc16sh_pred= gpr.predict(feat_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m8P9Bzlsu6p"
      },
      "source": [
        "<b> Interpolate the trained model onto these positions using the `.predict()` method. </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXg9ke9s928"
      },
      "source": [
        "<b> Unstandardize these values so that they are real dollars and put those into a column in `inc16sh` called `\"income_2000_interp\"`. </b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inc16sh. head (2)\n"
      ],
      "metadata": {
        "id": "iwRXoAYGQuJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1lBC2pus9u5"
      },
      "source": [
        "#Unstandardize target\n",
        "inc16sh[\"income_2000_interp\"]= inc16sh_pred * targ.std() + targ.mean()\n",
        "\n",
        "#Take the difference between 2016 and \"predicted\" 2000\n",
        "inc16sh[\"inc16sh_diff_pred\"]= inc16sh[\"income_2016\"] - inc16sh[\"ins16sh_pred\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inc16sh. head (2)"
      ],
      "metadata": {
        "id": "RHhcFzTUZbkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SCF4NN1tUz2"
      },
      "source": [
        "So now we have a column of interpolated values of the 2000 adjusted incomes at the locations of the 2016 census tracts.\n",
        "\n",
        "<b> Make a map of the difference between the 2016 median income and the adjusted 2000 median income using the `coolwarm` color map, `vmin=-20000` and `vmax=20000`. </b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labs = {\"inc16sh_diff_pred\": \"diff in median 2016 income & adjusted 2000 income\"}\n",
        "fig = px.choropleth_mapbox(inc16sh,\n",
        "                           geojson=inc16sh.set_index(\"AFFGEOID\"),\n",
        "locations=\"AFFGEOID\",\n",
        "color=\"inc16sh_diff_pred\", opacity=0.75,\n",
        "color_continuous_scale=\"RdBu\",\n",
        "title=\"Pennsylvania\",\n",
        "mapbox_style=\"carto-positron\",\n",
        "center={\"lon\": -75.15, \"lat\": 40.00},\n",
        "zoom=9.5,height=600, width=1200,labels=labs)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "STPL4PoiVlA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQbN-CA8lEyO"
      },
      "source": [
        "**Describe the spatial similarity between this map and the map of 2000/2016 demographic differences we derived in class.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the two sets of visualisations confirm the trend of segregation and median income decline.  In the 2000 and 2016 maps from the class, we see that fraction of white population is gaining ground in South-East and North in particular whereas the non-white fraction is shrinking. Those areas in this map also show the highest difference in income. We also see similarities between the concentration and shrinking of the non-white population in the class map and low median income in this map."
      ],
      "metadata": {
        "id": "B4imBJBxbucm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2EOSLlelPas"
      },
      "source": []
    }
  ]
}